---
layout: page
title: Stochastic optimization
description: >
  High-dimensional stochastic, non-convex optimization such as required to train neural networks.
img: assets/img/project_thumbnails/opt.png
importance: 29
category: research
---

Large datasets yield stochasticity in optimization since only a fraction of the data can be processed at a time.
This yields challenges since classical optimizers cannot be applied anymore.
Some of these challenges involve automation, parameter tuning, and finding good update rules in general.
But the scope of modern optimizers even goes beyond their classical goal of minimizing a function.
These are controlling the generalization gap, model selection by weight pruning, and even posterior estimation.
It is therefore less clear what the role of optimizers are these days.
I am interested in defining and exploring this new class of modern optimizers in the context
of a probabilistic description. 

Some aspects of stochastic optimization can be seen as methods of
[probabilistic numerics](https://en.wikipedia.org/wiki/Probabilistic_numerics).

### Related open source projects

---

- tbd

### Publications

---
- [Publication page]({{ site.baseurl }}{% link _pages/publications.md %})
- [PhD thesis](https://publikationen.uni-tuebingen.de/xmlui/handle/10900/84726)