<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Maren  Mahsereci


  | The Standard Error

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>Ω</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/blog/2021/std/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://mmahsereci.github.io/">
       <span class="font-weight-bold">Maren</span>   Mahsereci
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              <!-- I changed this -->
              posts
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      





<div class="post">

  <header class="post-header">
    <h1 class="post-title">The Standard Error</h1>
    <p class="post-meta">August 31, 2021 • mmahsereci</p>
    <p class="post-tags">
      <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a>
      
        ·  
        
        <a href="/blog/tag/statistics">
          <i class="fas fa-hashtag fa-sm"></i> statistics</a>  
          
      

      
        ·  
        
        <a href="/blog/category/techblog">
          <i class="fas fa-tag fa-sm"></i> techblog</a>  
          
      

    </p>
  </header>

  <article class="post-content">
    <p>The law of large numbers (<a href="/blog/2021/lln/">previous post</a>) 
can be combined with the standard error (SE) in order to
not only get an estimate of a parameter, but also a notion of the robustness of said estimate. Thus, the standard error
lets us know how confident we can be about our estimation.</p>

<p>In the <a href="/blog/2021/lln/">previous post</a>, we learned that, by the law of large numbers (LLN), the sample mean 
\(\bar{x}_n\) tends to the population mean \(\mu\) in some sense for large enough \(n\) 
(see <a href="/blog/2021/lln/">previous post</a> for notation). 
We have also empirically observed (for fair coin tosses with \(\mu=0.5\)) that the sample size \(n\) needs not 
be overly large (roughly \(&gt; 100\)) in order to yield a somewhat relivable estimate of the coin-flip-parameter \(\mu\).</p>

<p>Similarly, we have observed that the statistic \(\bar{x}_n\) by definition is a random number, as it is the average of
random coin tosses. For any finite \(n\) the statistic \(\bar{x}_n\) thus exhibits a certain variability which means 
that it’s value might be different if we repeat the experiment and toss the coin another \(n\) times 
(and then compute \(\bar{x}_n\) from the new coin tosses/ the new sample). 
The standard error \(\sigma_n\) quantifies this variability. In particular the SE has the following form</p>

\[SE[\bar{x}_n] = \frac{\sigma}{\sqrt{n}},\]

<p>where \(\sigma := \operatorname{Std}[x]\) is the standard deviation of the random variable \(x\) that represents 
a single coin toss. It is apparent that the SE drops proportional to one over the squareroot of \(n\), that is
\(SE[\bar{x}_n] \propto n^{-\frac{1}{2}}\). This behavior is called the <em>squareroot law</em>.</p>

<h4 id="how-wrong-can-it-be-the-most--important-characteristic-of-the-se">How wrong can it be? The most (?) important characteristic of the SE</h4>

<p>In addition to the squareroot law, we observe that the SE is independent of the population size 
as it only depends on the population variance \(\sigma^2\) and the sample size \(n\).
This is surprising but also very useful as it means that a low variability of the statistic 
\(\bar{x}_n\) for a large population can be achieved with a similar sample size as for a small population.
As example, let’s consider two countries, one of them small, and one of them large in population, and
(for the sake of argument) both currently having the same approval rate \(\mu\) of their presidents
(in this particular example, this implies same \(\sigma\)).
The SE formula now states that in order to obtain the same expected precision on the statistic \(\bar{x}_n\) representing 
the approval rate of each president, the survey conducted in the large country requires the identical (relatively small) sample size \(n\) 
as the survey conducted in the small country.
In other words, each survey simply needs to select a few hundred to a few thousand random voters to obtain
a statistic of good enough representative power, no matter the size of the country.
There are of course practical limitations to consider (some are briefly mentioned below), 
but this astonishing characteristic of the SE holds in theory and has proven successful in practice as well. 
Let’s have a closer look at the SE formula now, and introduce some notation. 
Then, we’ll empirically observe the behavior of the SE on the example of coin tosses.</p>

<h4 id="the-standard-error-formula">The Standard Error Formula</h4>

<p>Let \(\zeta_1, \dots, \zeta_k\) be uncorrelated (not necessarily independent or identically 
distributed) random variables, that is 
\(\operatorname{Cov}[\zeta_j, \zeta_l] = 0\) if \(j\neq l\) and \(j, l=1,\dots, l\) 
with corresponding variances \(\sigma^2_{\zeta_j}:=\operatorname{Var}[\zeta_j]\), \(j=1,\dots, k\).
Then, <a href="https://en.wikipedia.org/wiki/Variance#Sum_of_uncorrelated_variables_(Bienaym%C3%A9_formula)" target="_blank" rel="noopener noreferrer">Bienaymé’s formula</a> 
states that the variance of the sum \(S_k^{\zeta} :=\sum_{j=1}^k \zeta_j\) is equal to the 
sum of the variances of the \(\zeta\)s, that is \(\operatorname{Var}[S_k^{\zeta}] = \sum_{j=1}^k \sigma^2_{\zeta_j}\).</p>

<p>In our example, the single coin tosses \(x_i\) comprising the sample are uncorrelated as they are independent, and, 
as they are identically distributed, all have same variance \(\sigma^2\). 
Hence, the variance of their sum \(S_{n}^x:=\sum_{i=1}^n x_n\) is \(n\) times the variance of \(x\) that is
\(\operatorname{Var}[S_n^x] = \sum_{i=1}^n \operatorname{Var}[x_i] = \sum_{i=1}^n \sigma^2 = n\sigma^2\). 
The SE of \(\bar{x}_n\) which is equal to its 
standard deviation is thus</p>

\[SE[\bar{x}_n] 
= SE\left[\frac{S_n^x}{n}\right]  
= \frac{1}{n} SE[S_n^x] 
= \frac{1}{n}\sqrt{\operatorname{Var}[S_n^x]} = \frac{1}{n} \sqrt{\sigma^2 n} = \frac{\sigma}{\sqrt{n}},\]

<p>which (equality of leftmost and rightmost term) is the formula stated above. 
We’ll illustrate the SE again with the example of fair coin tosses.</p>

<h3 id="tossing-coins-again">Tossing Coins Again</h3>

<p>A single fair coin toss \(x\) follows a Bernoulli distribution with parameter \(\mu=0.5\). 
We know that Bernoulli random numbers have variance \(\sigma^2 = \mu(1-\mu)\). 
Hence, we can compute the statistic \(\bar{x}_n\) and the SE as
\(SE[\bar{x}_n] = \frac{\sqrt{\mu(1-\mu)}}{\sqrt{n}} = \frac{0.5}{\sqrt{n}}\).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># fair coin
</span><span class="n">mu</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1"># Bernoulli samples: 1 means heads, 0 means tails
</span><span class="n">n_samples</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mf">1e4</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">mu</span><span class="p">)</span>

<span class="c1"># Compute mean statistic and its standard error
</span><span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">cumsum</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span>  <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">S</span> <span class="o">/</span> <span class="n">n</span>
<span class="n">standard_errors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">mu</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">mu</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</code></pre></div></div>

<p>First we plot \(\bar{x}_n\) versus the number of samples \(n\) (blue solid). 
The horizontal gray line indicates the ground truth \(\mu=0.5\).
We observe that \(\bar{x}_n\) approaches \(\mu\) for larger \(n\); this is due to the law of large numbers (LLN).
The x-axis is in log-scale on all plots.</p>

<div style="text-align:center">
  <img src="/assets/posts/2021-08-31-std/00.png" style="width:90%; padding-top: 10px; padding-bottom: 10px;">
</div>

<p>Now we plot both \(\bar{x}_n\) (solid blue) and the interval \(\bar{x}_n\pm \frac{0.5}{\sqrt{n}}\) (dashed blue). 
We observe that the area between the dashed lines most of the time (for most \(n\)) but not every time 
encloses the true parameter \(\mu\). We also observe that the interval shrinks the larger \(n\) according to
the squareroot law.</p>

<div style="text-align:center">
  <img src="/assets/posts/2021-08-31-std/02.png" style="width:90%; padding-top: 10px; padding-bottom: 10px;">
</div>

<p>The plot below is a zoomed in version of the above plot for samples sizes between \(n=400,\dots,900\). 
It is better visible here that not all intervals enclose \(\mu\).</p>

<div style="text-align:center">
  <img src="/assets/posts/2021-08-31-std/02a.png" style="width:90%; padding-top: 10px; padding-bottom: 10px;">
</div>

<p>To illustrate the decay of the SE, we also plot the standalone \(SE[\bar{x}_n] = \frac{0.5}{\sqrt{n}}\) 
on a linear y-scale,</p>

<div style="text-align:center">
  <img src="/assets/posts/2021-08-31-std/03.png" style="width:90%; padding-top: 10px; padding-bottom: 10px;">
</div>

<p>and on a logarithmic y-scale. In the logarithmic plot we can better observe the linear decay 
\(\log SE[\bar{x}_n] \propto -\frac{1}{2}\log n\) with slope \(-\frac{1}{2}\).</p>

<div style="text-align:center">
  <img src="/assets/posts/2021-08-31-std/03a.png" style="width:90%; padding-top: 10px; padding-bottom: 10px;">
</div>

<h3 id="the-catch-again">The Catch Again</h3>

<p>Besides, requiring truly random numbers which (as mentioned in the <a href="/blog/2021/lln/">previous post</a>) are hard to obtain, the SE
formula has two major drawbacks.</p>

<p>First, the decay rate of the SE \(n^{-\frac{1}{2}}\) is very slow. It means that e.g., 4 times the sample size
will only half the standard error, 100 times the sample size will reduce the SE by 1/10th, and \(10^4\) times the 
sample size will only reduce the SE by a factor of 100 etc. 
It is apparent that the sample size required to obtain small SEs explodes pretty fast.
Therefore, it is very hard to obtain high precision estimates with
this method. The root cause of this is the underlying random sampling mechanism.
However, for rough but still reliable estimates, the statistic \(\bar{x}_n\) together with its SE 
is an incredibly valuable tool. With some further assumptions on the form of \(p(\bar{x}_n)\) that are
often justified in practice, one can even use the SE to obtain confidence intervals. 
But this is a topic for another post :)</p>

<p>Second, it requires us to know the population variance \(\sigma^2\) which in practice is
usually not accessible (to compute it we would require access to the whole population which is precisely not what we want).
In the example above, this did not matter as we had access to the ground truth values \(\sigma^2\) and \(\mu\).
This is usually not the case.
Generally, how this is handled is via the <em>boostrap principle</em>, where either i) \(\sigma^2\) is being estimated 
from the sample, or ii) the SE is being estimated via boostrap sampling. 
But this, too, is a topic for another post :)</p>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2024 Maren  Mahsereci.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
